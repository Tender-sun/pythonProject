{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    label                                            content\n0       0  ﻿ 第 章全 不知 幻想 一个 童话国 里 住 男孩儿 女孩儿 丁点儿 男孩儿 女孩儿 叫做...\n1       0  ﻿ 第一章 万事通 战胜 小星星 教授 全 不知 太阳城 旅行 回来 已经 过去 两年 半 ...\n2       0  ﻿ 第 章 花城 矮子 一座 童话 城市 里 住 矮子 管 叫 矮子 是因为 很小 每个 矮...\n3       0  一个 贵族 女儿 　 　 风儿 草 吹 过去 时候 田野 就 像 湖水 一起 涟漪 麦子 扫...\n4       0  一朵 叫 童话 蒲公英 斑马 一起 奔跑 一个 懒洋洋 季节 茉莉 正 坐在 树 发呆 一匹...\n..    ...                                                ...\n651     1  第 章鸡王 　 　 西双版纳 盛行 斗鸡 逢年过节 村村寨寨 都 举行 斗鸡 会 热闹 要 ...\n652     1  麻瓜 魔女 永恒 天使 第 章 序幕 　 　 天使 之城 老 天使 拉索 魔法 独 坐在 隐...\n653     1  　 　 一个 清澈 透明 冰晶 建造 宫殿 中 一个 蓝色 侏儒 坐在 冰雪 宝座 之上 殿...\n654     1  第 章 母熊 大白 掌 　 　 老 猎人 亢浪隆 山林 里 闯荡 几十年 飞禽走兽 大半辈子...\n655     1  第 章 爸爸 出差 回来 　 　 冬至 一天 艾晚 爸爸 艾 忠义 福建 出差 回来 　 　...\n\n[656 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>content</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>﻿ 第 章全 不知 幻想 一个 童话国 里 住 男孩儿 女孩儿 丁点儿 男孩儿 女孩儿 叫做...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>﻿ 第一章 万事通 战胜 小星星 教授 全 不知 太阳城 旅行 回来 已经 过去 两年 半 ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>﻿ 第 章 花城 矮子 一座 童话 城市 里 住 矮子 管 叫 矮子 是因为 很小 每个 矮...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>一个 贵族 女儿 　 　 风儿 草 吹 过去 时候 田野 就 像 湖水 一起 涟漪 麦子 扫...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>一朵 叫 童话 蒲公英 斑马 一起 奔跑 一个 懒洋洋 季节 茉莉 正 坐在 树 发呆 一匹...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>651</th>\n      <td>1</td>\n      <td>第 章鸡王 　 　 西双版纳 盛行 斗鸡 逢年过节 村村寨寨 都 举行 斗鸡 会 热闹 要 ...</td>\n    </tr>\n    <tr>\n      <th>652</th>\n      <td>1</td>\n      <td>麻瓜 魔女 永恒 天使 第 章 序幕 　 　 天使 之城 老 天使 拉索 魔法 独 坐在 隐...</td>\n    </tr>\n    <tr>\n      <th>653</th>\n      <td>1</td>\n      <td>一个 清澈 透明 冰晶 建造 宫殿 中 一个 蓝色 侏儒 坐在 冰雪 宝座 之上 殿...</td>\n    </tr>\n    <tr>\n      <th>654</th>\n      <td>1</td>\n      <td>第 章 母熊 大白 掌 　 　 老 猎人 亢浪隆 山林 里 闯荡 几十年 飞禽走兽 大半辈子...</td>\n    </tr>\n    <tr>\n      <th>655</th>\n      <td>1</td>\n      <td>第 章 爸爸 出差 回来 　 　 冬至 一天 艾晚 爸爸 艾 忠义 福建 出差 回来 　 　...</td>\n    </tr>\n  </tbody>\n</table>\n<p>656 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df  =pd.read_csv('../Data/csv/version1.csv').astype(str)\n",
    "df = df.drop(\"Unnamed: 0\",axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array([1,3,4])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "a"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1],\n       [3],\n       [4]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:,None]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1],\n       [3],\n       [4]])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import jieba\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts(df['content'])\n",
    "vocab=tokenizer.word_index #得到每个词的编号\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['content'], df['label'], test_size=0.2)\n",
    "x_train_word_ids=tokenizer.texts_to_sequences(x_train)\n",
    "x_test_word_ids = tokenizer.texts_to_sequences(x_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "读取词向量模型，对所有词语向量化，如果在模型中没出现过，都按零向量处理"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from gensim.models import keyedvectors\n",
    "import gensim\n",
    "import numpy as np\n",
    "#w2v=keyedvectors.load_word2vec_format(os.path.join(root_path,\"wiki_word2vec_50.bin\"),binary=True)\n",
    "w2v_model = gensim.models.KeyedVectors.load_word2vec_format(\"../Data/word2vec/wiki_word2vec_50.bin\",binary=True)\n",
    "embedding_matrix = np.zeros((len(vocab) + 1, 50))\n",
    "for word, i in vocab.items():\n",
    "    try:\n",
    "        embedding_vector = w2v_model[str(word)]\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    except KeyError:\n",
    "        continue"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "from keras import  Input\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding,Conv1D,MaxPooling1D,Flatten,Dense,Dropout,BatchNormalization\n",
    "import sklearn.metrics as metrics\n",
    "def TextCNN_model_2(x_train_padded_seqs,y_train,x_test_padded_seqs,y_test,embedding_matrix,shape1):\n",
    "    # 模型结构：词嵌入-卷积池化*3-拼接-全连接-dropout-全连接\n",
    "    main_input = Input(shape=(shape1,), dtype='float64')\n",
    "    # 词嵌入（使用预训练的词向量）\n",
    "    embedder = Embedding(len(vocab) + 1, 50, input_length=shape1, weights=[embedding_matrix], trainable=False)\n",
    "    embed = embedder(main_input)\n",
    "    # 词窗大小分别为3,4,5\n",
    "    cnn1 = Conv1D(256, 3, padding='same', strides=1, activation='relu')(embed)\n",
    "    cnn1 = MaxPooling1D(pool_size=38)(cnn1)\n",
    "    cnn2 = Conv1D(256, 4, padding='same', strides=1, activation='relu')(embed)\n",
    "    cnn2 = MaxPooling1D(pool_size=37)(cnn2)\n",
    "    cnn3 = Conv1D(256, 5, padding='same', strides=1, activation='relu')(embed)\n",
    "    cnn3 = MaxPooling1D(pool_size=36)(cnn3)\n",
    "    # 合并三个模型的输出向量\n",
    "    cnn = concatenate([cnn1, cnn2, cnn3], axis=1)\n",
    "    flat = Flatten()(cnn)\n",
    "    drop = Dropout(0.4)(flat)\n",
    "    main_output = Dense(2, activation='softmax')(drop)\n",
    "    model = Model(inputs=main_input, outputs=main_output)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    one_hot_labels = np_utils.to_categorical(y_train, num_classes=2)  # 将标签转换为one-hot编码\n",
    "    model.fit(x_train_padded_seqs, one_hot_labels, batch_size=32, epochs=25)\n",
    "    #y_test_onehot = keras.utils.to_categorical(y_test, num_classes=3)  # 将标签转换为one-hot编码\n",
    "    result = model.predict(x_test_padded_seqs)  # 预测样本属于每个类别的概率\n",
    "    result_labels = np.argmax(result, axis=1)  # 获得最大概率对应的标签\n",
    "    y_predict = list(map(str, result_labels))\n",
    "    y_pred = list(result_labels)\n",
    "    t_test = list(y_test)\n",
    "    #print(y_pred)\n",
    "    print('准确率', metrics.accuracy_score(y_test, y_predict))\n",
    "    print('平均f1-score:', metrics.f1_score(y_test, y_predict, average='weighted'))\n",
    "#TextCNN_model_2(x_train_padded_seqs,y_train,x_test_padded_seqs,y_test,embedding_matrix,)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 1.3049 - accuracy: 0.5420\n",
      "Epoch 2/25\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.6562 - accuracy: 0.6603\n",
      "Epoch 3/25\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.4830 - accuracy: 0.7691\n",
      "Epoch 4/25\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.4131 - accuracy: 0.8111\n",
      "Epoch 5/25\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.3293 - accuracy: 0.8950\n",
      "Epoch 6/25\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.3033 - accuracy: 0.8912\n",
      "Epoch 7/25\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.2571 - accuracy: 0.9313\n",
      "Epoch 8/25\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.2157 - accuracy: 0.9427\n",
      "Epoch 9/25\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1975 - accuracy: 0.9466\n",
      "Epoch 10/25\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1873 - accuracy: 0.9504\n",
      "Epoch 11/25\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1726 - accuracy: 0.9504\n",
      "Epoch 12/25\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1453 - accuracy: 0.9580\n",
      "Epoch 13/25\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1482 - accuracy: 0.9523\n",
      "Epoch 14/25\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1660 - accuracy: 0.9523\n",
      "Epoch 15/25\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1421 - accuracy: 0.9523\n",
      "Epoch 16/25\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1381 - accuracy: 0.9504\n",
      "Epoch 17/25\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1300 - accuracy: 0.9542\n",
      "Epoch 18/25\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1181 - accuracy: 0.9504\n",
      "Epoch 19/25\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1554 - accuracy: 0.9561\n",
      "Epoch 20/25\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1232 - accuracy: 0.9542\n",
      "Epoch 21/25\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.1605 - accuracy: 0.9523\n",
      "Epoch 22/25\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1395 - accuracy: 0.9447\n",
      "Epoch 23/25\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.1057 - accuracy: 0.9656\n",
      "Epoch 24/25\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1064 - accuracy: 0.9447\n",
      "Epoch 25/25\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0956 - accuracy: 0.9618\n",
      "[1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0]\n",
      "准确率 0.6439393939393939\n",
      "平均f1-score: 0.6425981050727501\n"
     ]
    }
   ],
   "source": [
    "x_train_padded_seqs=pad_sequences(x_train_word_ids,maxlen=500) #将超过固定值的部分截掉，不足的在最前面用0填充\n",
    "x_test_padded_seqs=pad_sequences(x_test_word_ids, maxlen=500)\n",
    "TextCNN_model_2(x_train_padded_seqs,y_train,x_test_padded_seqs,y_test,embedding_matrix,500)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62     0\n",
      "165    0\n",
      "574    1\n",
      "307    0\n",
      "586    1\n",
      "      ..\n",
      "26     0\n",
      "187    0\n",
      "166    0\n",
      "226    0\n",
      "112    0\n",
      "Name: label, Length: 132, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-26-3aaf935e6aec>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0my_pred\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "从50词到10000词训练查看结果"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "p = 50\n",
    "for i in range(200):\n",
    "    x_train_padded_seqs=pad_sequences(x_train_word_ids,maxlen=p) #将超过固定值的部分截掉，不足的在最前面用0填充\n",
    "    x_test_padded_seqs=pad_sequences(x_test_word_ids, maxlen=p)\n",
    "    print(\"词汇量\",p)\n",
    "    TextCNN_model_2(x_train_padded_seqs,y_train,x_test_padded_seqs,y_test,embedding_matrix,p)\n",
    "    p+=50"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}