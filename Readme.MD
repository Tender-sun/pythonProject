# 基于深度学习小学生读物分类v2.0

**注意：**
本项目源数据来自于正版数据平台，一千九百多本txt文件仅用于科研实验，请勿商用

本项目是基于深度学习和机器学习的读物分类项目，主要分类小学读物。
相比于v1.0版本的主要不同点
 - 更换了机器学习方法
 - 引进了textcnn的深度学习算法
 - 扩大了数据集规模
 - 三分类模型，将小学细分为低年级和高年级，和非小学类进行分类
 - 

**v1.0 repo传送链接{这里将去年国创开源，做成另一个仓库}**

**v1.0 paper传送链接{这里附上去年ACM会议的论文收录链接或者文件链接}**

**这里附上这次的论文链接**

**联系方式**

了解更多项目内容请提交issues或联系邮箱sunr2019@lzu.edu.cn



### 1、项目背景介绍

小学生读物存在着分类不规范等问题。本项目通过运用大数据、机器学习、推荐系统等热门技术建立一个科学、客观以及可计算的适合小学生的图书推荐模型，期望与目前基于主观推荐的规则模型形相辅相成，为培养小学生的阅读习惯提出更科学的指导，为目前国内存在的小学生阅读方式和阅读质量等问题提供解决思路，培养小学生的阅读习惯，提高小学生的阅读能力，提升小学生的阅读水平。

### 2、数据源介绍

选取一千多本书，分为三类。低年级类，高年级类和非小学类。
由于版权数据来源和数据本身不进行公布，仅用于科研使用非商业用途可以issue or email

每类350本，最后选取328本。

**数据集组成**
 - 0——表示小学低年级类书籍（328）
 - 1——表示小学高年级类书籍（328）
 - 2——表示不适合小学类书籍（328）

简单示例
这里插入一个表格

| Label |      Name      | Content |
| :---: | :------------: | :-----: |
|   0   | 《阿拉伯童话》 |         |
|   0   |                |         |
|   0   |                |         |
|   0   |                |         |
|   1   |                |         |
|   1   |                |         |
|   1   |                |         |
|   1   |                |         |
|   2   |                |         |
|   2   |                |         |
|   2   |                |         |
|   2   |                |         |



### 3、所用算法介绍
算法原理均不详细介绍，这里仅展示所用到算法。
- **机器学习**
  1. SVM
  2. NB
  3. LR
  4. ADA
- **深度学习**
  1. TEXTCNN
  

深度学习需要一定的算力，本项目使用NVDIA GeForce GTX 1660 Ti
### 4、快速开始

```python
--Data
------csv
------data-book_resource
------data-vocabulary
------data-word_natural
------stop-words
--code
------Data pre-processing
-----------utf.py
-----------remove_adv&adr.py
------jieba分词.py
------TF-IDF.py
------机器学习方法.ipynb
------根据词性分类.ipynb
------textcnn实现.ipynb
------3分类.ipynb
--model
------wiki_word2vec_50.bin
------zhs_wiki_glove.vectors.100d.txt.txt
------glove.6B
```

#### 数据部分介绍

- **csv**  用来存放所有生成的csv，这里只上传了几个版本，可以根据自己情况执行jieba分词.py单独生成
- **data-book_resource** 用来存放所有书籍，如果最后要执行分类的请单独建立一个文件夹，并里面存放n,y两个文件夹。或者三个，如果选择三个请自行改一改代码结构，比较简单。这个文件夹中others有1400本，可以选出328本构成平衡数据集进行分类。
- **data-vocabulary** 这个文件家是小学生词汇库，里面包含一份整个小学的词语库，还包含两个区分高低年级的词库
- **data-word_natural** 这里面是对高低年级词语进行词性标注后分的类。每个年级包含5类（形容词、动词、名词、连词、副词）
- **stop-words** 这里面主要是一些停用词文件，这个在jieba分词过程中会读取，来判断分好的词语是否在停用词当中。



#### 词向量模型介绍

本文挑选了三种模型

- word2vec  **wiki_word2vec_50.bin**基于维基百科的中文语料训练模型，这里每一个词都被训练了50维度
- glove **zhs_wiki_glove.vectors.100d.txt.txt**这个也是基于wiki中文语料库训练的词向量模型，100维度。其中glove.6B是四个不同维度的词向量模型。可根据需求自己选即可。可以用gensim库将glove模型转为word2vec进行读取。

#### 整体流程

**4.1 数据预处理**

（执行下面步骤前，请将文件路径修改至适合）

首先利用数据预处理代码utf.py将所有书籍的编码格式全部转为utf-8编码，方便后续统一读取。

再利用remove_adv&adr.py，将获取的书籍中的广告信息删除，以及删除一些不想要的词汇等

****

**4.2、jieba分词&TF-IDF**

这一步是我们处理数据的部分，这一部分代码中，我们需要利用停用词文件，将书中所有停用词去除，并且利用正则化表达式去除一些特殊字符等。需要根据代码改好文件路径，这里面有三个路径，一个是存放源数据的文件夹，下面有两个子文件夹“n”和“y”。其他两个文件夹是用来存放分词结果的文件夹，需要对应改好名称。同时jieba分词.py会生成一个df并保存为csv文件

**csv示例**

|      | label |                           content                            |
| ---- | ----- | :----------------------------------------------------------: |
| 1    | 0     |         幻想, 一个, 童话国, 里, 住, 男孩儿, 女孩儿……         |
| 2    | 0     |  万事通, 战胜, 小星星, 教授, 全, 不知, 太阳城, 旅行, 回来…   |
| ……   | ……    |                             …………                             |
| 400  | 1     | 骚戏, 在此之前, 细读, 西门, 两部, 长篇小说, 敏感, 莲衣, 现实, 张扬, |
| 401  | 1     | 驼峰, 航线, 自序, 驼峰, 航线, 绵延, 千里, 终年, 白雪皑皑, 喜马拉雅山 |

上面是分词后产生的结果，data文件夹csv中便存放了几个这样的文件，其中其他类表示不适合小学生阅读的书籍生成的csv，version是将高低年级以不同标签分词存放的结果，version1和version2分别是再分词过程中用了不同的筛选条件，比如词频、词语长度等等限制



**TF-IDF**

这里是提取每本书中相关性比较高的一些词语，再拿去分类。由于精度不理想，这里没有上传对应的csv，如有需要可以重新执行代码生成

**4.3 分类实现**

我们根据jieba分词产生的词语文件，利用textcnn和机器学习算法进行分类。主要代码可以执行**textcnn实现.ipynb和机器学习方法**，在机器学习任务上一定要注意class_list的构建，注意数据维度。

其中三分类的实现中，一定要将算法中的标签属性 **num_classes**设置为3，并且三类标签只能是012，否则会报错。因为是onehot编码。

其中深度学习的代码中有很多参数可以调节，比如训练轮数，batchsize的大小，卷积词窗的大小，dropout要断开的神经网络比例等等等等参数。

**其中我们还根据词库的高低年纪词语词性，对每一本书进行编码**。每本书转为一个十维向量，再利用机器学习分类的方式进行书籍分类。可以根据文件《根据词性分类.ipynb》来复现这一工作。



**下面是整个项目代码的运行流程。**

![image-20220326121257912](Readme.assets/image-20220326121257912.png)

**引用**

如果我们的工作对您有帮助，欢迎引用我们的文章

[^Title]: Research on Elementary School Students’ Books Recommendation Algorithm Based on Words and Character Library

```
@inproceedings{chen2021research,
  title={Research on Elementary School Students’ Books Recommendation Algorithm Based on Words and Character Library},
  author={Chen, Yufeng and Ma, Jun and Du, Yaqiong and Sun, Rui and Niu, Bojuan},
  booktitle={2021 2nd International Conference on Artificial Intelligence and Information Systems},
  pages={1--5},
  year={2021}
}
```